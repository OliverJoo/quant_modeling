{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import OrderedDict\n",
    "from time import time\n",
    "from scipy.stats import spearmanr\n",
    "from logbook import Logger, StderrHandler, INFO\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from zipline.pipeline import Pipeline, CustomFactor\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "from zipline.pipeline.factors import AverageDollarVolume, EWMA, Returns\n",
    "from zipline.pipeline.factors.technical import RSI, MACDSignal, TrueRange\n",
    "from zipline import run_algorithm\n",
    "# although zipline.api have date_rules and time_rules, the error red underline has been shown. IDK abt this\n",
    "# maybe library version dependencies conflict? However, this program works well.\n",
    "from zipline.api import (attach_pipeline, pipeline_output, date_rules, time_rules, schedule_function,\n",
    "                         set_slippage, set_commission, record, order_target, order_target_percent)\n",
    "from zipline.finance import commission, slippage\n",
    "import pyfolio as pf\n",
    "from pyfolio.plotting import plot_rolling_returns, plot_rolling_sharpe\n",
    "from pyfolio.timeseries import forecast_cone_bootstrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Setup Logging\n",
    "log_handler = StderrHandler(format_string='[{record.time:%Y-%m-%d %H:%M:%S.%f}]: ' +\n",
    "                                          '{record.level_name}: {record.func_name}: {record.message}', level=INFO)\n",
    "log_handler.push_application()\n",
    "log = Logger('Algorithm')\n",
    "\n",
    "# Target long/short positions\n",
    "N_LONGS = 25\n",
    "N_SHORTS = 25\n",
    "MIN_POSITIONS = 15\n",
    "\n",
    "UNIVERSE = 250\n",
    "\n",
    "# Length of the training period (memory-intensive due to pre-processing)\n",
    "TRAINING_PERIOD = 252 * 2\n",
    "\n",
    "# train to predict 1 day forward returns\n",
    "N_FORWARD_DAYS = 1\n",
    "\n",
    "# How often to trade; align with prediction horizon - N_FORWARD_DAYS & TREADE_FREQ\n",
    "# for weekly, set to date_rules.week_start(days_offset=1)\n",
    "TRADE_FREQ = date_rules.every_day()\n",
    "\n",
    "# data has been created until 2018. Thus, this has been tested until the end of 2017\n",
    "start = pd.Timestamp('2015-01-01', tz='UTC').replace(tzinfo=None)\n",
    "end = pd.Timestamp('2017-12-31', tz='UTC').replace(tzinfo=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Factor Engineering 1 - Momentum1\n",
    "def Price_Momentum_3M():\n",
    "    return Returns(window_length=63)\n",
    "\n",
    "\n",
    "# Factor Engineering 1 - Momentum2\n",
    "def Returns_39W():\n",
    "    return Returns(window_length=215)\n",
    "\n",
    "\n",
    "# Factor Engineering 2 - Volatility\n",
    "# CustomFactor - User-defined function should be inherited the CustomFactor\n",
    "class Vol_3M(CustomFactor):\n",
    "    inputs = [Returns(window_length=2)]\n",
    "    window_length = 63 # 3 months\n",
    "\n",
    "    def compute(self, today, assets, out, rets):\n",
    "        out[:] = np.nanstd(rets, axis=0)\n",
    "\n",
    "\n",
    "# Factor Engineering 3 - Mean Reversion\n",
    "class Mean_Reversion_1M(CustomFactor):\n",
    "    # standardized difference between latest monthly return\n",
    "    # and their annual average\n",
    "    inputs = [Returns(window_length=21)]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, monthly_rets):\n",
    "        out[:] = (monthly_rets[-1] - np.nanmean(monthly_rets, axis=0)) / np.nanstd(monthly_rets, axis=0)\n",
    "\n",
    "\n",
    "# Factor Engineering 4 - Money Flow Volume\n",
    "class Moneyflow_Volume_5d(CustomFactor):\n",
    "    inputs = [USEquityPricing.close, USEquityPricing.volume]\n",
    "    window_length = 5\n",
    "\n",
    "    def compute(self, today, assets, out, close, volume):\n",
    "        mfvs = []\n",
    "\n",
    "        for col_c, col_v in zip(close.T, volume.T):\n",
    "            # denominator\n",
    "            denominator = np.dot(col_c, col_v)\n",
    "            # numerator\n",
    "            numerator = 0.\n",
    "            for n, price in enumerate(col_c.tolist()):\n",
    "                if price > col_c[n - 1]:\n",
    "                    numerator += price * col_v[n]\n",
    "                else:\n",
    "                    numerator -= price * col_v[n]\n",
    "\n",
    "            mfvs.append(numerator / denominator)\n",
    "        out[:] = mfvs\n",
    "\n",
    "\n",
    "# Factor Engineering 5 - Price Trend\n",
    "class Trendline(CustomFactor): # trend regression for 1y\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, close):\n",
    "        X = np.arange(self.window_length).reshape(-1, 1).astype(float)\n",
    "        X -= X.mean()\n",
    "        Y = close - np.nanmean(close, axis=0)  # np.nanmean: mean value that Nan ignored\n",
    "        out[:] = (X.T @ Y / np.var(X)) / self.window_length\n",
    "\n",
    "# Factor Engineering 6 - Oscillator\n",
    "class Price_Oscillator(CustomFactor):\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, close):\n",
    "        four_week_period = close[-20:]\n",
    "        out[:] = (np.nanmean(four_week_period, axis=0) / np.nanmean(close, axis=0)) - 1.\n",
    "\n",
    "# Combine Features\n",
    "vol_3M = Vol_3M()\n",
    "mean_reversion_1M = Mean_Reversion_1M()\n",
    "macd_signal_10d = MACDSignal()\n",
    "moneyflow_volume_5d = Moneyflow_Volume_5d()\n",
    "trendline = Trendline()\n",
    "price_oscillator = Price_Oscillator()\n",
    "price_momentum_3M = Price_Momentum_3M()\n",
    "returns_39W = Returns_39W()\n",
    "true_range = TrueRange()\n",
    "\n",
    "features = {\n",
    "    'Vol 3M': vol_3M,\n",
    "    'Mean Reversion 1M': mean_reversion_1M,\n",
    "    'MACD Signal 10d': macd_signal_10d,\n",
    "    'Moneyflow Volume 5D': moneyflow_volume_5d,\n",
    "    'Trendline': trendline,\n",
    "    'Price Oscillator': price_oscillator,\n",
    "    'Price Momentum 3M': price_momentum_3M,\n",
    "    '39 Week Returns': returns_39W,\n",
    "    'True Range': true_range\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LinearModel(CustomFactor):\n",
    "    train_on_weekday = [0, 2, 4] # 3 times training per week\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(self, *args, **kwargs)\n",
    "        self._scaler = StandardScaler()\n",
    "        self._model = SGDRegressor(penalty='L2')\n",
    "        self._trained = False\n",
    "\n",
    "    # chk whether executing training or not\n",
    "    def _maybe_train_model(self, today, returns, inputs):\n",
    "        if (today.weekday() in self.train_on_weekday) or not self._trained:\n",
    "            self._train_model(today, returns, inputs)\n",
    "\n",
    "    def _train_model(self, today, returns, inputs):\n",
    "        scaler = self._scaler\n",
    "        model = self._model\n",
    "\n",
    "        shift_by = N_FORWARD_DAYS + 1\n",
    "        outcome = returns[shift_by:].flatten()\n",
    "        features = np.dstack(inputs)[:-shift_by]\n",
    "        n_days, n_stocks, n_features = features.shape\n",
    "        features = features.reshape(-1, n_features)\n",
    "        features = features[~np.isnan(outcome)]\n",
    "        outcome = outcome[~np.isnan(outcome)]\n",
    "        outcome = outcome[np.all(~np.isnan(features), axis=1)]\n",
    "        features = features[np.all(~np.isnan(features), axis=1)]\n",
    "        features = scaler.fit_transform(features)\n",
    "\n",
    "        start = time()\n",
    "        model.fit(X=features, y=outcome)\n",
    "        log.info('{} | {:.2f}s'.format(today.date(), time() - start))\n",
    "        self._trained = True\n",
    "\n",
    "    def compute(self, today, assets, out, returns, *inputs):\n",
    "        self._maybe_train_model(today, returns, inputs)\n",
    "\n",
    "        # Predict most recent feature values\n",
    "        X = np.dstack(inputs)[-1]\n",
    "        missing = np.any(np.isnan(X), axis=1)\n",
    "        X[missing, :] = 0\n",
    "        X = self._scaler.transform(X)\n",
    "        preds = self._model.predict(X)\n",
    "        out[:] = np.where(missing, np.nan, preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ML Pipeline\n",
    "def make_ml_pipeline(universe, window_length=21, n_forward_days=5):\n",
    "    pipeline_columns = OrderedDict()\n",
    "\n",
    "    # ensure that returns is the first input\n",
    "    pipeline_columns['Returns'] = Returns(inputs=[USEquityPricing.open], mask=universe,\n",
    "                                          window_length=n_forward_days + 1)\n",
    "\n",
    "    # convert factors to ranks; append to pipeline\n",
    "    pipeline_columns.update({k: v.rank(mask=universe) for k, v in features.items()})\n",
    "\n",
    "    # Create ML pipeline factor.\n",
    "    # window_length : training period\n",
    "    pipeline_columns['predictions'] = LinearModel(inputs=pipeline_columns.values(),\n",
    "                                                  window_length=window_length + n_forward_days,\n",
    "                                                  mask=universe)\n",
    "\n",
    "    return Pipeline(screen=universe, columns=pipeline_columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Universe\n",
    "def make_universe():\n",
    "    # Set screen\n",
    "    dollar_volume = AverageDollarVolume(window_length=90)\n",
    "    return dollar_volume.top(UNIVERSE)\n",
    "\n",
    "universe = make_universe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Initialize Algorithm\n",
    "def initialize(context):\n",
    "    set_slippage(slippage.FixedSlippage(spread=0.00))\n",
    "    set_commission(commission.PerShare(cost=0, min_trade_cost=0))\n",
    "\n",
    "    schedule_function(rebalance, TRADE_FREQ, date_rules.every_day(), time_rules.market_open(hours=1, minutes=30), )\n",
    "\n",
    "    schedule_function(record_vars, date_rules.every_day(), time_rules.market_close())\n",
    "\n",
    "    ml_pipeline = make_ml_pipeline(universe, n_forward_days=N_FORWARD_DAYS, window_length=TRAINING_PERIOD)\n",
    "\n",
    "    # Create our dynamic stock selector.\n",
    "    attach_pipeline(ml_pipeline, 'ml_model')\n",
    "\n",
    "    context.past_predictions = {}\n",
    "    context.ic = 0\n",
    "    context.rmse = 0\n",
    "    context.mae = 0\n",
    "    context.returns_spread_bps = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Evaluate Predictive Accuracy\n",
    "def evaluate_predictions(output, context):\n",
    "    # past predictions to evaluate MDL performance\n",
    "    # A day has passed, shift days and drop old ones as series data\n",
    "    context.past_predictions = {k - 1: v for k, v in context.past_predictions.items() if k > 0}\n",
    "\n",
    "    if 0 in context.past_predictions:\n",
    "        # Use today's n-day returns as future returns to evaluate predictions\n",
    "        returns, predictions = (output['Returns'].dropna()\n",
    "                                .align(context.past_predictions[0].dropna(), join='inner'))\n",
    "        if len(returns) > 0 and len(predictions) > 0:\n",
    "            context.ic = spearmanr(returns, predictions)[0]\n",
    "            context.rmse = np.sqrt(mean_squared_error(returns, predictions))\n",
    "            context.mae = mean_absolute_error(returns, predictions)\n",
    "\n",
    "            long_rets = returns[predictions > 0].mean()\n",
    "            short_rets = returns[predictions < 0].mean()\n",
    "            context.returns_spread_bps = (long_rets - short_rets) * 10000\n",
    "\n",
    "    # Store current predictions\n",
    "    context.past_predictions[N_FORWARD_DAYS] = context.predicted_returns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# called every day b4 MKT Open\n",
    "def before_trading_start(context, data):\n",
    "    output = pipeline_output('ml_model')\n",
    "    context.predicted_returns = output['predictions']\n",
    "    context.predicted_returns.index.set_names(['equity'], inplace=True)\n",
    "\n",
    "    evaluate_predictions(output, context)\n",
    "\n",
    "    # These are the securities that we are interested in trading each day.\n",
    "    context.security_list = context.predicted_returns.index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# execute orders and change positions by schedule_function() timing\n",
    "def rebalance(context, data):\n",
    "    predictions = context.predicted_returns\n",
    "\n",
    "    # Drop stocks that can not be traded\n",
    "    predictions = predictions.loc[data.can_trade(predictions.index)]\n",
    "    longs = (predictions[predictions > 0].sort_values(ascending=False)[:N_LONGS].index.tolist())\n",
    "    shorts = (predictions[predictions < 0].sort_values()[:N_SHORTS].index.tolist())\n",
    "    targets = set(longs + shorts)\n",
    "    for position in context.portfolio.positions:\n",
    "        if position not in targets:\n",
    "            order_target(position, 0)\n",
    "\n",
    "    n_longs, n_shorts = len(longs), len(shorts)\n",
    "    if n_longs > MIN_POSITIONS and n_shorts > MIN_POSITIONS:\n",
    "        for stock in longs:\n",
    "            order_target_percent(stock, target=1 / n_longs)\n",
    "        for stock in shorts:\n",
    "            order_target_percent(stock, target=-1 / n_shorts)\n",
    "    else:\n",
    "        for stock in targets:\n",
    "            if stock in context.portfolio.positions:\n",
    "                order_target(stock, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def record_vars(context, data):\n",
    "    record(leverage=context.account.leverage, ic=context.ic, rmse=context.rmse, mae=context.mae,\n",
    "           returns_spread_bps=context.returns_spread_bps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no data for bundle 'quandl' on or before 2023-09-01 07:43:54.283983+00:00\nmaybe you need to run: $ zipline ingest -b quandl",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mD:\\99.Dev\\Anaconda\\envs\\ml4t\\lib\\site-packages\\zipline\\data\\bundles\\core.py:488\u001B[0m, in \u001B[0;36m_make_bundle_core.<locals>.most_recent_data\u001B[1;34m(bundle_name, timestamp, environ)\u001B[0m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 488\u001B[0m     candidates \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpth\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbundle_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menviron\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    491\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pth\u001B[38;5;241m.\u001B[39mdata_path(\n\u001B[0;32m    492\u001B[0m         [\n\u001B[0;32m    493\u001B[0m             bundle_name,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    499\u001B[0m         environ\u001B[38;5;241m=\u001B[39menviron,\n\u001B[0;32m    500\u001B[0m     )\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\99.Dev\\\\Python\\\\pythonProject\\\\Scripts\\\\data\\\\quandl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m go \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrun_algorithm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitialize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbefore_trading_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbefore_trading_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mcapital_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdaily\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbenchmark_returns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mquandl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(time() \u001B[38;5;241m-\u001B[39m go))\n",
      "File \u001B[1;32mD:\\99.Dev\\Anaconda\\envs\\ml4t\\lib\\site-packages\\zipline\\utils\\run_algo.py:397\u001B[0m, in \u001B[0;36mrun_algorithm\u001B[1;34m(start, end, initialize, capital_base, handle_data, before_trading_start, analyze, data_frequency, bundle, bundle_timestamp, trading_calendar, metrics_set, benchmark_returns, default_extension, extensions, strict_extensions, environ, custom_loader, blotter)\u001B[0m\n\u001B[0;32m    393\u001B[0m load_extensions(default_extension, extensions, strict_extensions, environ)\n\u001B[0;32m    395\u001B[0m benchmark_spec \u001B[38;5;241m=\u001B[39m BenchmarkSpec\u001B[38;5;241m.\u001B[39mfrom_returns(benchmark_returns)\n\u001B[1;32m--> 397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhandle_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhandle_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitialize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbefore_trading_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbefore_trading_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43manalyze\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manalyze\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43malgofile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43malgotext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_frequency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapital_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapital_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbundle_timestamp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbundle_timestamp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevnull\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrading_calendar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrading_calendar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprint_algo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_namespace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43menviron\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mblotter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblotter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbenchmark_spec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbenchmark_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\99.Dev\\Anaconda\\envs\\ml4t\\lib\\site-packages\\zipline\\utils\\run_algo.py:93\u001B[0m, in \u001B[0;36m_run\u001B[1;34m(handle_data, initialize, before_trading_start, analyze, algofile, algotext, defines, data_frequency, capital_base, bundle, bundle_timestamp, start, end, output, trading_calendar, print_algo, metrics_set, local_namespace, environ, blotter, custom_loader, benchmark_spec)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run\u001B[39m(\n\u001B[0;32m     65\u001B[0m     handle_data,\n\u001B[0;32m     66\u001B[0m     initialize,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     86\u001B[0m     benchmark_spec,\n\u001B[0;32m     87\u001B[0m ):\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;124;03m\"\"\"Run a backtest for the given algorithm.\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \n\u001B[0;32m     90\u001B[0m \u001B[38;5;124;03m    This is shared between the cli and :func:`zipline.run_algo`.\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 93\u001B[0m     bundle_data \u001B[38;5;241m=\u001B[39m \u001B[43mbundles\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43menviron\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbundle_timestamp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trading_calendar \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m         trading_calendar \u001B[38;5;241m=\u001B[39m get_calendar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXNYS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\99.Dev\\Anaconda\\envs\\ml4t\\lib\\site-packages\\zipline\\data\\bundles\\core.py:532\u001B[0m, in \u001B[0;36m_make_bundle_core.<locals>.load\u001B[1;34m(name, environ, timestamp)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timestamp \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    531\u001B[0m     timestamp \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mTimestamp\u001B[38;5;241m.\u001B[39mutcnow()\n\u001B[1;32m--> 532\u001B[0m timestr \u001B[38;5;241m=\u001B[39m \u001B[43mmost_recent_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menviron\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m BundleData(\n\u001B[0;32m    534\u001B[0m     asset_finder\u001B[38;5;241m=\u001B[39mAssetFinder(\n\u001B[0;32m    535\u001B[0m         asset_db_path(name, timestr, environ\u001B[38;5;241m=\u001B[39menviron),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    545\u001B[0m     ),\n\u001B[0;32m    546\u001B[0m )\n",
      "File \u001B[1;32mD:\\99.Dev\\Anaconda\\envs\\ml4t\\lib\\site-packages\\zipline\\data\\bundles\\core.py:504\u001B[0m, in \u001B[0;36m_make_bundle_core.<locals>.most_recent_data\u001B[1;34m(bundle_name, timestamp, environ)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merrno\u001B[39m\u001B[38;5;124m\"\u001B[39m, errno\u001B[38;5;241m.\u001B[39mENOENT) \u001B[38;5;241m!=\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    505\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno data for bundle \u001B[39m\u001B[38;5;132;01m{bundle!r}\u001B[39;00m\u001B[38;5;124m on or before \u001B[39m\u001B[38;5;132;01m{timestamp}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaybe you need to run: $ zipline ingest -b \u001B[39m\u001B[38;5;132;01m{bundle}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    507\u001B[0m         bundle\u001B[38;5;241m=\u001B[39mbundle_name,\n\u001B[0;32m    508\u001B[0m         timestamp\u001B[38;5;241m=\u001B[39mtimestamp,\n\u001B[0;32m    509\u001B[0m     ),\n\u001B[0;32m    510\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: no data for bundle 'quandl' on or before 2023-09-01 07:43:54.283983+00:00\nmaybe you need to run: $ zipline ingest -b quandl"
     ]
    }
   ],
   "source": [
    "go = time()\n",
    "results = run_algorithm(start=start, end=end, initialize=initialize, before_trading_start=before_trading_start,\n",
    "                        capital_base=1e6, data_frequency='daily', benchmark_returns=None, bundle='quandl')\n",
    "\n",
    "print('{:.2f}'.format(time() - go))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "axes = (results[['ic', 'returns_spread_bps']].dropna().rolling(21).mean()\n",
    "        .plot(subplots=True, layout=(2, 1), figsize=(14, 6),\n",
    "              title=['Informmation Coefficient (21-day Rolling Avg.)',\n",
    "                     'Returns Spread (bps, 21-day Rolling Avg.)'],\n",
    "              legend=False))\n",
    "axes = axes.flatten()\n",
    "axes[0].set_ylabel('IC')\n",
    "axes[1].set_ylabel('bps')\n",
    "plt.suptitle('Model Performance', fontsize=14)\n",
    "plt.subplots_adjust(top=.9);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get PyFolio Input\n",
    "returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(results)\n",
    "\n",
    "# Get BM Data\n",
    "benchmark = web.DataReader('SP500', 'fred', '2014', '2018').squeeze()\n",
    "benchmark = benchmark.pct_change().tz_localize('UTC')\n",
    "\n",
    "# Custom Performance Plots\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 5))\n",
    "plot_rolling_returns(returns, factor_returns=benchmark, live_start_date='2017-01-01', logy=False,\n",
    "                     cone_std=2, legend_loc='best', volatility_match=False,\n",
    "                     cone_function=forecast_cone_bootstrap, ax=axes[0])\n",
    "plot_rolling_sharpe(returns, ax=axes[1])\n",
    "axes[0].set_title('Cumulative Returns - In and Out-of-Sample')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=benchmark,\n",
    "                          live_start_date='2017-01-01', round_trips=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import empyrical, pyfolio\n",
    "\n",
    "empyrical.__version__\n",
    "pyfolio.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
