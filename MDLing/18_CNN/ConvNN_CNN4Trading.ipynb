{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils4t import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "size = 15\n",
    "lookahead = 1\n",
    "\n",
    "results_path = Path('results', 'cnn_for_trading')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2416051 entries, ('A', Timestamp('2001-01-02 00:00:00')) to ('ZTS', Timestamp('2018-03-27 00:00:00'))\n",
      "Columns: 225 entries, 01_CMO to 11_WMA\n",
      "dtypes: float32(195), float64(30)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Load Model Data\n",
    "with pd.HDFStore('data/universe_data.h5') as store:\n",
    "    features = store['img_data']\n",
    "    targets = store['targets']\n",
    "features.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                      01_CMO    01_ROC   01_NATR    01_PPO   01_MACD  \\\nsymbol date                                                            \nA      2001-01-02 -34.412796 -0.973141  6.947728  0.585962  0.534434   \n       2001-01-03  12.697194  2.633023  7.902791  1.489047  0.594177   \n       2001-01-04  25.371769  8.878505  7.599194  2.874703  0.748755   \n       2001-01-05  -0.667682 -1.573114  8.137382  2.481612  0.687998   \n       2001-01-08 -12.974548 -3.724462  8.088328  1.464707  0.534037   \n       2001-01-09 -14.725676 -3.196347  7.756344  0.662250  0.393383   \n       2001-01-10   6.201897  8.706761  7.151905  1.021115  0.403544   \n       2001-01-11  22.686089  2.547657  6.885161  2.109057  0.528496   \n       2001-01-12   8.185741 -3.639485  6.569717  2.223989  0.542454   \n       2001-01-16  23.762115  5.684708  6.123020  3.042057  0.658498   \n\n                     01_CMA    01_RMW    01_HML  01_Market    01_SMB  ...  \\\nsymbol date                                                           ...   \nA      2001-01-02  0.025279 -0.006478 -0.016951   0.013758 -0.011674  ...   \n       2001-01-03  0.014975 -0.008856 -0.018188   0.009819 -0.020037  ...   \n       2001-01-04  0.005857 -0.002693 -0.021231   0.004036 -0.009937  ...   \n       2001-01-05  0.000882 -0.003614 -0.013796   0.005879 -0.005555  ...   \n       2001-01-08 -0.019798 -0.003292  0.017045   0.014734  0.015989  ...   \n       2001-01-09 -0.057114 -0.016250  0.077492   0.023451  0.046154  ...   \n       2001-01-10 -0.080198 -0.032393  0.107490   0.018679  0.061976  ...   \n       2001-01-11 -0.035940 -0.019112  0.033739   0.005908  0.027541  ...   \n       2001-01-12 -0.033253 -0.013577  0.029525   0.008077  0.021867  ...   \n       2001-01-16 -0.021099  0.001203  0.010575   0.012431  0.019688  ...   \n\n                     11_CMA    11_RMW    11_HML  11_Market    11_SMB  \\\nsymbol date                                                            \nA      2001-01-02 -0.000318  0.001430 -0.002984   0.017752  0.008332   \n       2001-01-03  0.000321  0.002027 -0.004751   0.017179  0.006739   \n       2001-01-04 -0.000894  0.002713 -0.006307   0.016025  0.010261   \n       2001-01-05 -0.001228  0.001167 -0.004730   0.016212  0.009304   \n       2001-01-08  0.000942  0.001341 -0.005059   0.017432  0.010896   \n       2001-01-09  0.003383  0.003184 -0.008622   0.017611  0.009998   \n       2001-01-10  0.002964  0.002954 -0.008293   0.017326  0.009965   \n       2001-01-11  0.002584  0.002016 -0.007086   0.017121  0.009000   \n       2001-01-12  0.002168  0.002470 -0.006528   0.017463  0.007894   \n       2001-01-16  0.002428  0.002848 -0.007988   0.016461  0.007431   \n\n                     11_BBH    11_BBL     11_RSI     11_EMA     11_WMA  \nsymbol date                                                             \nA      2001-01-02  0.151378  0.004491  46.341988  36.953236  37.318766  \n       2001-01-03  0.066146  0.090595  54.497822  37.110993  37.350420  \n       2001-01-04  0.034141  0.120748  57.293777  37.420349  37.568837  \n       2001-01-05  0.080985  0.075976  52.150497  37.437270  37.528706  \n       2001-01-08  0.102645  0.049909  49.463108  37.306922  37.354283  \n       2001-01-09  0.095221  0.044919  49.090408  37.171844  37.184575  \n       2001-01-10  0.055356  0.081671  52.609795  37.238066  37.231630  \n       2001-01-11  0.020442  0.114962  55.785439  37.477090  37.467154  \n       2001-01-12  0.041336  0.093935  53.361328  37.573217  37.585091  \n       2001-01-16  0.016178  0.120144  56.280544  37.823378  37.873037  \n\n[10 rows x 225 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>01_CMO</th>\n      <th>01_ROC</th>\n      <th>01_NATR</th>\n      <th>01_PPO</th>\n      <th>01_MACD</th>\n      <th>01_CMA</th>\n      <th>01_RMW</th>\n      <th>01_HML</th>\n      <th>01_Market</th>\n      <th>01_SMB</th>\n      <th>...</th>\n      <th>11_CMA</th>\n      <th>11_RMW</th>\n      <th>11_HML</th>\n      <th>11_Market</th>\n      <th>11_SMB</th>\n      <th>11_BBH</th>\n      <th>11_BBL</th>\n      <th>11_RSI</th>\n      <th>11_EMA</th>\n      <th>11_WMA</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"10\" valign=\"top\">A</th>\n      <th>2001-01-02</th>\n      <td>-34.412796</td>\n      <td>-0.973141</td>\n      <td>6.947728</td>\n      <td>0.585962</td>\n      <td>0.534434</td>\n      <td>0.025279</td>\n      <td>-0.006478</td>\n      <td>-0.016951</td>\n      <td>0.013758</td>\n      <td>-0.011674</td>\n      <td>...</td>\n      <td>-0.000318</td>\n      <td>0.001430</td>\n      <td>-0.002984</td>\n      <td>0.017752</td>\n      <td>0.008332</td>\n      <td>0.151378</td>\n      <td>0.004491</td>\n      <td>46.341988</td>\n      <td>36.953236</td>\n      <td>37.318766</td>\n    </tr>\n    <tr>\n      <th>2001-01-03</th>\n      <td>12.697194</td>\n      <td>2.633023</td>\n      <td>7.902791</td>\n      <td>1.489047</td>\n      <td>0.594177</td>\n      <td>0.014975</td>\n      <td>-0.008856</td>\n      <td>-0.018188</td>\n      <td>0.009819</td>\n      <td>-0.020037</td>\n      <td>...</td>\n      <td>0.000321</td>\n      <td>0.002027</td>\n      <td>-0.004751</td>\n      <td>0.017179</td>\n      <td>0.006739</td>\n      <td>0.066146</td>\n      <td>0.090595</td>\n      <td>54.497822</td>\n      <td>37.110993</td>\n      <td>37.350420</td>\n    </tr>\n    <tr>\n      <th>2001-01-04</th>\n      <td>25.371769</td>\n      <td>8.878505</td>\n      <td>7.599194</td>\n      <td>2.874703</td>\n      <td>0.748755</td>\n      <td>0.005857</td>\n      <td>-0.002693</td>\n      <td>-0.021231</td>\n      <td>0.004036</td>\n      <td>-0.009937</td>\n      <td>...</td>\n      <td>-0.000894</td>\n      <td>0.002713</td>\n      <td>-0.006307</td>\n      <td>0.016025</td>\n      <td>0.010261</td>\n      <td>0.034141</td>\n      <td>0.120748</td>\n      <td>57.293777</td>\n      <td>37.420349</td>\n      <td>37.568837</td>\n    </tr>\n    <tr>\n      <th>2001-01-05</th>\n      <td>-0.667682</td>\n      <td>-1.573114</td>\n      <td>8.137382</td>\n      <td>2.481612</td>\n      <td>0.687998</td>\n      <td>0.000882</td>\n      <td>-0.003614</td>\n      <td>-0.013796</td>\n      <td>0.005879</td>\n      <td>-0.005555</td>\n      <td>...</td>\n      <td>-0.001228</td>\n      <td>0.001167</td>\n      <td>-0.004730</td>\n      <td>0.016212</td>\n      <td>0.009304</td>\n      <td>0.080985</td>\n      <td>0.075976</td>\n      <td>52.150497</td>\n      <td>37.437270</td>\n      <td>37.528706</td>\n    </tr>\n    <tr>\n      <th>2001-01-08</th>\n      <td>-12.974548</td>\n      <td>-3.724462</td>\n      <td>8.088328</td>\n      <td>1.464707</td>\n      <td>0.534037</td>\n      <td>-0.019798</td>\n      <td>-0.003292</td>\n      <td>0.017045</td>\n      <td>0.014734</td>\n      <td>0.015989</td>\n      <td>...</td>\n      <td>0.000942</td>\n      <td>0.001341</td>\n      <td>-0.005059</td>\n      <td>0.017432</td>\n      <td>0.010896</td>\n      <td>0.102645</td>\n      <td>0.049909</td>\n      <td>49.463108</td>\n      <td>37.306922</td>\n      <td>37.354283</td>\n    </tr>\n    <tr>\n      <th>2001-01-09</th>\n      <td>-14.725676</td>\n      <td>-3.196347</td>\n      <td>7.756344</td>\n      <td>0.662250</td>\n      <td>0.393383</td>\n      <td>-0.057114</td>\n      <td>-0.016250</td>\n      <td>0.077492</td>\n      <td>0.023451</td>\n      <td>0.046154</td>\n      <td>...</td>\n      <td>0.003383</td>\n      <td>0.003184</td>\n      <td>-0.008622</td>\n      <td>0.017611</td>\n      <td>0.009998</td>\n      <td>0.095221</td>\n      <td>0.044919</td>\n      <td>49.090408</td>\n      <td>37.171844</td>\n      <td>37.184575</td>\n    </tr>\n    <tr>\n      <th>2001-01-10</th>\n      <td>6.201897</td>\n      <td>8.706761</td>\n      <td>7.151905</td>\n      <td>1.021115</td>\n      <td>0.403544</td>\n      <td>-0.080198</td>\n      <td>-0.032393</td>\n      <td>0.107490</td>\n      <td>0.018679</td>\n      <td>0.061976</td>\n      <td>...</td>\n      <td>0.002964</td>\n      <td>0.002954</td>\n      <td>-0.008293</td>\n      <td>0.017326</td>\n      <td>0.009965</td>\n      <td>0.055356</td>\n      <td>0.081671</td>\n      <td>52.609795</td>\n      <td>37.238066</td>\n      <td>37.231630</td>\n    </tr>\n    <tr>\n      <th>2001-01-11</th>\n      <td>22.686089</td>\n      <td>2.547657</td>\n      <td>6.885161</td>\n      <td>2.109057</td>\n      <td>0.528496</td>\n      <td>-0.035940</td>\n      <td>-0.019112</td>\n      <td>0.033739</td>\n      <td>0.005908</td>\n      <td>0.027541</td>\n      <td>...</td>\n      <td>0.002584</td>\n      <td>0.002016</td>\n      <td>-0.007086</td>\n      <td>0.017121</td>\n      <td>0.009000</td>\n      <td>0.020442</td>\n      <td>0.114962</td>\n      <td>55.785439</td>\n      <td>37.477090</td>\n      <td>37.467154</td>\n    </tr>\n    <tr>\n      <th>2001-01-12</th>\n      <td>8.185741</td>\n      <td>-3.639485</td>\n      <td>6.569717</td>\n      <td>2.223989</td>\n      <td>0.542454</td>\n      <td>-0.033253</td>\n      <td>-0.013577</td>\n      <td>0.029525</td>\n      <td>0.008077</td>\n      <td>0.021867</td>\n      <td>...</td>\n      <td>0.002168</td>\n      <td>0.002470</td>\n      <td>-0.006528</td>\n      <td>0.017463</td>\n      <td>0.007894</td>\n      <td>0.041336</td>\n      <td>0.093935</td>\n      <td>53.361328</td>\n      <td>37.573217</td>\n      <td>37.585091</td>\n    </tr>\n    <tr>\n      <th>2001-01-16</th>\n      <td>23.762115</td>\n      <td>5.684708</td>\n      <td>6.123020</td>\n      <td>3.042057</td>\n      <td>0.658498</td>\n      <td>-0.021099</td>\n      <td>0.001203</td>\n      <td>0.010575</td>\n      <td>0.012431</td>\n      <td>0.019688</td>\n      <td>...</td>\n      <td>0.002428</td>\n      <td>0.002848</td>\n      <td>-0.007988</td>\n      <td>0.016461</td>\n      <td>0.007431</td>\n      <td>0.016178</td>\n      <td>0.120144</td>\n      <td>56.280544</td>\n      <td>37.823378</td>\n      <td>37.873037</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 225 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                    r01_fwd  r01dec_fwd   r05_fwd  r05dec_fwd\nsymbol date                                                  \nA      2001-01-02  0.103184         7.0  0.041667         6.0\n       2001-01-03  0.037769         8.0 -0.014609         5.0\n       2001-01-04 -0.054764         2.0 -0.011845         4.0\n       2001-01-05 -0.032873         1.0  0.019433         5.0\n       2001-01-08 -0.004695         4.0  0.092770         7.0\n       2001-01-09  0.043585         8.0  0.168679         8.0\n       2001-01-10  0.040680         7.0  0.221479         9.0\n       2001-01-11 -0.024844         2.0  0.138985         9.0\n       2001-01-12  0.036701         8.0  0.117940         9.0\n       2001-01-16  0.064444         9.0  0.078364         7.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>r01_fwd</th>\n      <th>r01dec_fwd</th>\n      <th>r05_fwd</th>\n      <th>r05dec_fwd</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"10\" valign=\"top\">A</th>\n      <th>2001-01-02</th>\n      <td>0.103184</td>\n      <td>7.0</td>\n      <td>0.041667</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-03</th>\n      <td>0.037769</td>\n      <td>8.0</td>\n      <td>-0.014609</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-04</th>\n      <td>-0.054764</td>\n      <td>2.0</td>\n      <td>-0.011845</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-05</th>\n      <td>-0.032873</td>\n      <td>1.0</td>\n      <td>0.019433</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-08</th>\n      <td>-0.004695</td>\n      <td>4.0</td>\n      <td>0.092770</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-09</th>\n      <td>0.043585</td>\n      <td>8.0</td>\n      <td>0.168679</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-10</th>\n      <td>0.040680</td>\n      <td>7.0</td>\n      <td>0.221479</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-11</th>\n      <td>-0.024844</td>\n      <td>2.0</td>\n      <td>0.138985</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-12</th>\n      <td>0.036701</td>\n      <td>8.0</td>\n      <td>0.117940</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2001-01-16</th>\n      <td>0.064444</td>\n      <td>9.0</td>\n      <td>0.078364</td>\n      <td>7.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((1208025, 225), (1208025, 4))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features[:int(len(features)/2)]\n",
    "targets = targets[:int(len(targets)/2)]\n",
    "\n",
    "features.shape, targets.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1208025 entries, ('A', Timestamp('2001-01-02 00:00:00')) to ('JNPR', Timestamp('2012-08-14 00:00:00'))\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   r01_fwd     1207668 non-null  float64\n",
      " 1   r01dec_fwd  1207667 non-null  float64\n",
      " 2   r05_fwd     1206240 non-null  float64\n",
      " 3   r05dec_fwd  1206240 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 41.7+ MB\n"
     ]
    }
   ],
   "source": [
    "targets.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "outcome = f'r{lookahead:02}_fwd'\n",
    "features = features.join(targets[[outcome]]).dropna()\n",
    "target = features[outcome]\n",
    "features = features.drop(outcome, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " CONV1 (Conv2D)              (None, 15, 15, 16)        160       \n",
      "                                                                 \n",
      " CONV2 (Conv2D)              (None, 15, 15, 32)        4640      \n",
      "                                                                 \n",
      " POOL2 (MaxPooling2D)        (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " DROP1 (Dropout)             (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " FLAT1 (Flatten)             (None, 1568)              0         \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 32)                50208     \n",
      "                                                                 \n",
      " DROP2 (Dropout)             (None, 32)                0         \n",
      "                                                                 \n",
      " FC2 (Dense)                 (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,041\n",
      "Trainable params: 55,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "def make_model(filter1=16, act1='relu', filter2=32, act2='relu', do1=.25, do2=.5, dense=32):\n",
    "    input_shape = (size, size, 1)\n",
    "    cnn = Sequential([\n",
    "        Conv2D(filters=filter1, kernel_size=3, padding='same', activation=act1, input_shape=input_shape,\n",
    "               name='CONV1'),\n",
    "        Conv2D(filters=filter2, kernel_size=3, padding='same', activation=act2, name='CONV2'),\n",
    "        MaxPooling2D(pool_size=2, name='POOL2'),\n",
    "        Dropout(do1, name='DROP1'),\n",
    "        Flatten(name='FLAT1'),\n",
    "        Dense(dense, activation='relu', name='FC1'),\n",
    "        Dropout(do2, name='DROP2'),\n",
    "        Dense(1, activation='linear', name='FC2')\n",
    "    ])\n",
    "    cnn.compile(loss='mse',\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
    "                                                  nesterov=False, name='SGD'),\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    return cnn\n",
    "\n",
    "cnn = make_model()\n",
    "cnn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "train_period_length = 5 * 12 * 21\n",
    "test_period_length = 5 * 21\n",
    "n_splits = 16\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits, train_period_length=train_period_length,\n",
    "                          test_period_length=test_period_length, lookahead=lookahead)\n",
    "\n",
    "def get_train_valid_data(X, y, train_idx, test_idx):\n",
    "    x_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    x_val, y_val = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    return (x_train.reshape(-1, size, size, 1), y_train, x_val.reshape(-1, size, size, 1), y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5331/5331 [==============================] - 26s 3ms/step - loss: 3.9476e-04 - rmse: 0.0199 - val_loss: 3.7491e-04 - val_rmse: 0.0194\n",
      "Epoch 2/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.6020e-04 - rmse: 0.0190 - val_loss: 3.7463e-04 - val_rmse: 0.0194\n",
      "Epoch 3/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5943e-04 - rmse: 0.0190 - val_loss: 3.7412e-04 - val_rmse: 0.0193\n",
      "Epoch 4/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5934e-04 - rmse: 0.0190 - val_loss: 3.7427e-04 - val_rmse: 0.0193\n",
      "Epoch 5/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5922e-04 - rmse: 0.0190 - val_loss: 3.7461e-04 - val_rmse: 0.0194\n",
      "Epoch 6/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5908e-04 - rmse: 0.0189 - val_loss: 3.7411e-04 - val_rmse: 0.0193\n",
      "Epoch 7/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5876e-04 - rmse: 0.0189 - val_loss: 3.7411e-04 - val_rmse: 0.0193\n",
      "Epoch 8/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5889e-04 - rmse: 0.0189 - val_loss: 3.7408e-04 - val_rmse: 0.0193\n",
      "Epoch 9/10\n",
      "5331/5331 [==============================] - 17s 3ms/step - loss: 3.5899e-04 - rmse: 0.0189 - val_loss: 3.7418e-04 - val_rmse: 0.0193\n",
      "Epoch 10/10\n",
      "5331/5331 [==============================] - 16s 3ms/step - loss: 3.5886e-04 - rmse: 0.0189 - val_loss: 3.7409e-04 - val_rmse: 0.0193\n",
      "00:03:04 | fold:01 | Mean:-0.0143 | Median:-0.0139\n",
      "Epoch 1/10\n",
      "5405/5405 [==============================] - 17s 3ms/step - loss: 4.3149e-04 - rmse: 0.0208 - val_loss: 2.3938e-04 - val_rmse: 0.0155\n",
      "Epoch 2/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7284e-04 - rmse: 0.0193 - val_loss: 2.3939e-04 - val_rmse: 0.0155\n",
      "Epoch 3/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7228e-04 - rmse: 0.0193 - val_loss: 2.3883e-04 - val_rmse: 0.0155\n",
      "Epoch 4/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7193e-04 - rmse: 0.0193 - val_loss: 2.3937e-04 - val_rmse: 0.0155\n",
      "Epoch 5/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7196e-04 - rmse: 0.0193 - val_loss: 2.3896e-04 - val_rmse: 0.0155\n",
      "Epoch 6/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7209e-04 - rmse: 0.0193 - val_loss: 2.3883e-04 - val_rmse: 0.0155\n",
      "Epoch 7/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7181e-04 - rmse: 0.0193 - val_loss: 2.4011e-04 - val_rmse: 0.0155\n",
      "Epoch 8/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7216e-04 - rmse: 0.0193 - val_loss: 2.3965e-04 - val_rmse: 0.0155\n",
      "Epoch 9/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7198e-04 - rmse: 0.0193 - val_loss: 2.3910e-04 - val_rmse: 0.0155\n",
      "Epoch 10/10\n",
      "5405/5405 [==============================] - 16s 3ms/step - loss: 3.7194e-04 - rmse: 0.0193 - val_loss: 2.4037e-04 - val_rmse: 0.0155\n",
      "00:05:51 | fold:02 | Mean:-0.0064 | Median:-0.0140\n",
      "Epoch 1/10\n",
      "5457/5457 [==============================] - 17s 3ms/step - loss: 4.1834e-04 - rmse: 0.0205 - val_loss: 2.3962e-04 - val_rmse: 0.0155\n",
      "Epoch 2/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8333e-04 - rmse: 0.0196 - val_loss: 2.3818e-04 - val_rmse: 0.0154\n",
      "Epoch 3/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8293e-04 - rmse: 0.0196 - val_loss: 2.3860e-04 - val_rmse: 0.0154\n",
      "Epoch 4/10\n",
      "5457/5457 [==============================] - 17s 3ms/step - loss: 3.8260e-04 - rmse: 0.0196 - val_loss: 2.3814e-04 - val_rmse: 0.0154\n",
      "Epoch 5/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8253e-04 - rmse: 0.0196 - val_loss: 2.3815e-04 - val_rmse: 0.0154\n",
      "Epoch 6/10\n",
      "5457/5457 [==============================] - 17s 3ms/step - loss: 3.8239e-04 - rmse: 0.0196 - val_loss: 2.3795e-04 - val_rmse: 0.0154\n",
      "Epoch 7/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8243e-04 - rmse: 0.0196 - val_loss: 2.3958e-04 - val_rmse: 0.0155\n",
      "Epoch 8/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8243e-04 - rmse: 0.0196 - val_loss: 2.3818e-04 - val_rmse: 0.0154\n",
      "Epoch 9/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8233e-04 - rmse: 0.0196 - val_loss: 2.3804e-04 - val_rmse: 0.0154\n",
      "Epoch 10/10\n",
      "5457/5457 [==============================] - 16s 3ms/step - loss: 3.8220e-04 - rmse: 0.0195 - val_loss: 2.3914e-04 - val_rmse: 0.0155\n",
      "00:08:38 | fold:03 | Mean:-0.0136 | Median:-0.0319\n",
      "Epoch 1/10\n",
      "5489/5489 [==============================] - 17s 3ms/step - loss: 4.8953e-04 - rmse: 0.0221 - val_loss: 3.6572e-04 - val_rmse: 0.0191\n",
      "Epoch 2/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3442e-04 - rmse: 0.0208 - val_loss: 3.6321e-04 - val_rmse: 0.0191\n",
      "Epoch 3/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3401e-04 - rmse: 0.0208 - val_loss: 3.6325e-04 - val_rmse: 0.0191\n",
      "Epoch 4/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3385e-04 - rmse: 0.0208 - val_loss: 3.6407e-04 - val_rmse: 0.0191\n",
      "Epoch 5/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3385e-04 - rmse: 0.0208 - val_loss: 3.6479e-04 - val_rmse: 0.0191\n",
      "Epoch 6/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3376e-04 - rmse: 0.0208 - val_loss: 3.6407e-04 - val_rmse: 0.0191\n",
      "Epoch 7/10\n",
      "5489/5489 [==============================] - 16s 3ms/step - loss: 4.3373e-04 - rmse: 0.0208 - val_loss: 3.6326e-04 - val_rmse: 0.0191\n",
      "Epoch 8/10\n",
      "5489/5489 [==============================] - 17s 3ms/step - loss: 4.3363e-04 - rmse: 0.0208 - val_loss: 3.6493e-04 - val_rmse: 0.0191\n",
      "Epoch 9/10\n",
      "5489/5489 [==============================] - 17s 3ms/step - loss: 4.3362e-04 - rmse: 0.0208 - val_loss: 3.6352e-04 - val_rmse: 0.0191\n",
      "Epoch 10/10\n",
      "5489/5489 [==============================] - 17s 3ms/step - loss: 4.3361e-04 - rmse: 0.0208 - val_loss: 3.6518e-04 - val_rmse: 0.0191\n",
      "00:11:27 | fold:04 | Mean: 0.0153 | Median: 0.0242\n",
      "Epoch 1/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.4885e-04 - rmse: 0.0212 - val_loss: 4.8888e-04 - val_rmse: 0.0221\n",
      "Epoch 2/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.2034e-04 - rmse: 0.0205 - val_loss: 4.9042e-04 - val_rmse: 0.0221\n",
      "Epoch 3/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1981e-04 - rmse: 0.0205 - val_loss: 4.8897e-04 - val_rmse: 0.0221\n",
      "Epoch 4/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1972e-04 - rmse: 0.0205 - val_loss: 4.9116e-04 - val_rmse: 0.0222\n",
      "Epoch 5/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1938e-04 - rmse: 0.0205 - val_loss: 4.8931e-04 - val_rmse: 0.0221\n",
      "Epoch 6/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1951e-04 - rmse: 0.0205 - val_loss: 4.8915e-04 - val_rmse: 0.0221\n",
      "Epoch 7/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1943e-04 - rmse: 0.0205 - val_loss: 4.9264e-04 - val_rmse: 0.0222\n",
      "Epoch 8/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1938e-04 - rmse: 0.0205 - val_loss: 4.8853e-04 - val_rmse: 0.0221\n",
      "Epoch 9/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1942e-04 - rmse: 0.0205 - val_loss: 4.8826e-04 - val_rmse: 0.0221\n",
      "Epoch 10/10\n",
      "5517/5517 [==============================] - 17s 3ms/step - loss: 4.1949e-04 - rmse: 0.0205 - val_loss: 4.8875e-04 - val_rmse: 0.0221\n",
      "00:14:19 | fold:05 | Mean: 0.0298 | Median: 0.0314\n",
      "Epoch 1/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 4.2157e-04 - rmse: 0.0205 - val_loss: 6.9636e-04 - val_rmse: 0.0264\n",
      "Epoch 2/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.9018e-04 - rmse: 0.0198 - val_loss: 6.9456e-04 - val_rmse: 0.0264\n",
      "Epoch 3/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8979e-04 - rmse: 0.0197 - val_loss: 6.9807e-04 - val_rmse: 0.0264\n",
      "Epoch 4/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8935e-04 - rmse: 0.0197 - val_loss: 6.9626e-04 - val_rmse: 0.0264\n",
      "Epoch 5/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8934e-04 - rmse: 0.0197 - val_loss: 6.9637e-04 - val_rmse: 0.0264\n",
      "Epoch 6/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8939e-04 - rmse: 0.0197 - val_loss: 6.9512e-04 - val_rmse: 0.0264\n",
      "Epoch 7/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8932e-04 - rmse: 0.0197 - val_loss: 6.9446e-04 - val_rmse: 0.0264\n",
      "Epoch 8/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8929e-04 - rmse: 0.0197 - val_loss: 6.9502e-04 - val_rmse: 0.0264\n",
      "Epoch 9/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8922e-04 - rmse: 0.0197 - val_loss: 6.9485e-04 - val_rmse: 0.0264\n",
      "Epoch 10/10\n",
      "5536/5536 [==============================] - 17s 3ms/step - loss: 3.8932e-04 - rmse: 0.0197 - val_loss: 6.9499e-04 - val_rmse: 0.0264\n",
      "00:17:13 | fold:06 | Mean:-0.0063 | Median:-0.0075\n",
      "Epoch 1/10\n",
      "5550/5550 [==============================] - 18s 3ms/step - loss: 4.2910e-04 - rmse: 0.0207 - val_loss: 4.4397e-04 - val_rmse: 0.0211\n",
      "Epoch 2/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0220e-04 - rmse: 0.0201 - val_loss: 4.4383e-04 - val_rmse: 0.0211\n",
      "Epoch 3/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0183e-04 - rmse: 0.0200 - val_loss: 4.4216e-04 - val_rmse: 0.0210\n",
      "Epoch 4/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0159e-04 - rmse: 0.0200 - val_loss: 4.4530e-04 - val_rmse: 0.0211\n",
      "Epoch 5/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0142e-04 - rmse: 0.0200 - val_loss: 4.3960e-04 - val_rmse: 0.0210\n",
      "Epoch 6/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0123e-04 - rmse: 0.0200 - val_loss: 4.4439e-04 - val_rmse: 0.0211\n",
      "Epoch 7/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0120e-04 - rmse: 0.0200 - val_loss: 4.4682e-04 - val_rmse: 0.0211\n",
      "Epoch 8/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0122e-04 - rmse: 0.0200 - val_loss: 4.4029e-04 - val_rmse: 0.0210\n",
      "Epoch 9/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0133e-04 - rmse: 0.0200 - val_loss: 4.3969e-04 - val_rmse: 0.0210\n",
      "Epoch 10/10\n",
      "5550/5550 [==============================] - 17s 3ms/step - loss: 4.0119e-04 - rmse: 0.0200 - val_loss: 4.4093e-04 - val_rmse: 0.0210\n",
      "00:20:07 | fold:07 | Mean: 0.0462 | Median: 0.0670\n",
      "Epoch 1/10\n",
      "5554/5554 [==============================] - 18s 3ms/step - loss: 4.6410e-04 - rmse: 0.0215 - val_loss: 3.4608e-04 - val_rmse: 0.0186\n",
      "Epoch 2/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0382e-04 - rmse: 0.0201 - val_loss: 3.4514e-04 - val_rmse: 0.0186\n",
      "Epoch 3/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0330e-04 - rmse: 0.0201 - val_loss: 3.4505e-04 - val_rmse: 0.0186\n",
      "Epoch 4/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0335e-04 - rmse: 0.0201 - val_loss: 3.4503e-04 - val_rmse: 0.0186\n",
      "Epoch 5/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0305e-04 - rmse: 0.0201 - val_loss: 3.4653e-04 - val_rmse: 0.0186\n",
      "Epoch 6/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0326e-04 - rmse: 0.0201 - val_loss: 3.4520e-04 - val_rmse: 0.0186\n",
      "Epoch 7/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0330e-04 - rmse: 0.0201 - val_loss: 3.5004e-04 - val_rmse: 0.0187\n",
      "Epoch 8/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0324e-04 - rmse: 0.0201 - val_loss: 3.4861e-04 - val_rmse: 0.0187\n",
      "Epoch 9/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0315e-04 - rmse: 0.0201 - val_loss: 3.4507e-04 - val_rmse: 0.0186\n",
      "Epoch 10/10\n",
      "5554/5554 [==============================] - 17s 3ms/step - loss: 4.0316e-04 - rmse: 0.0201 - val_loss: 3.4533e-04 - val_rmse: 0.0186\n",
      "00:23:05 | fold:08 | Mean: 0.0185 | Median: 0.0163\n",
      "Epoch 1/10\n",
      "5562/5562 [==============================] - 18s 3ms/step - loss: 4.6309e-04 - rmse: 0.0215 - val_loss: 2.9180e-04 - val_rmse: 0.0171\n",
      "Epoch 2/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3442e-04 - rmse: 0.0208 - val_loss: 2.8821e-04 - val_rmse: 0.0170\n",
      "Epoch 3/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3400e-04 - rmse: 0.0208 - val_loss: 2.8904e-04 - val_rmse: 0.0170\n",
      "Epoch 4/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3378e-04 - rmse: 0.0208 - val_loss: 2.8794e-04 - val_rmse: 0.0170\n",
      "Epoch 5/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3362e-04 - rmse: 0.0208 - val_loss: 2.8746e-04 - val_rmse: 0.0170\n",
      "Epoch 6/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3359e-04 - rmse: 0.0208 - val_loss: 2.8739e-04 - val_rmse: 0.0170\n",
      "Epoch 7/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3354e-04 - rmse: 0.0208 - val_loss: 2.8841e-04 - val_rmse: 0.0170\n",
      "Epoch 8/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3347e-04 - rmse: 0.0208 - val_loss: 2.8757e-04 - val_rmse: 0.0170\n",
      "Epoch 9/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3354e-04 - rmse: 0.0208 - val_loss: 2.8727e-04 - val_rmse: 0.0169\n",
      "Epoch 10/10\n",
      "5562/5562 [==============================] - 17s 3ms/step - loss: 4.3345e-04 - rmse: 0.0208 - val_loss: 2.8762e-04 - val_rmse: 0.0170\n",
      "00:26:01 | fold:09 | Mean: 0.0019 | Median: 0.0027\n",
      "Epoch 1/10\n",
      "5564/5564 [==============================] - 18s 3ms/step - loss: 6.4321e-04 - rmse: 0.0254 - val_loss: 2.7344e-04 - val_rmse: 0.0165\n",
      "Epoch 2/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9557e-04 - rmse: 0.0244 - val_loss: 2.7608e-04 - val_rmse: 0.0166\n",
      "Epoch 3/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9492e-04 - rmse: 0.0244 - val_loss: 2.7316e-04 - val_rmse: 0.0165\n",
      "Epoch 4/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9482e-04 - rmse: 0.0244 - val_loss: 2.7266e-04 - val_rmse: 0.0165\n",
      "Epoch 5/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9458e-04 - rmse: 0.0244 - val_loss: 2.7405e-04 - val_rmse: 0.0166\n",
      "Epoch 6/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9446e-04 - rmse: 0.0244 - val_loss: 2.7267e-04 - val_rmse: 0.0165\n",
      "Epoch 7/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9471e-04 - rmse: 0.0244 - val_loss: 2.7572e-04 - val_rmse: 0.0166\n",
      "Epoch 8/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9450e-04 - rmse: 0.0244 - val_loss: 2.7327e-04 - val_rmse: 0.0165\n",
      "Epoch 9/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9464e-04 - rmse: 0.0244 - val_loss: 2.7353e-04 - val_rmse: 0.0165\n",
      "Epoch 10/10\n",
      "5564/5564 [==============================] - 17s 3ms/step - loss: 5.9450e-04 - rmse: 0.0244 - val_loss: 2.7322e-04 - val_rmse: 0.0165\n",
      "00:28:56 | fold:10 | Mean: 0.0202 | Median: 0.0228\n",
      "Epoch 1/10\n",
      "5567/5567 [==============================] - 18s 3ms/step - loss: 9.2805e-04 - rmse: 0.0305 - val_loss: 2.7723e-04 - val_rmse: 0.0167\n",
      "Epoch 2/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.9023e-04 - rmse: 0.0298 - val_loss: 2.8515e-04 - val_rmse: 0.0169\n",
      "Epoch 3/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8982e-04 - rmse: 0.0298 - val_loss: 2.8252e-04 - val_rmse: 0.0168\n",
      "Epoch 4/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8956e-04 - rmse: 0.0298 - val_loss: 2.7713e-04 - val_rmse: 0.0166\n",
      "Epoch 5/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8944e-04 - rmse: 0.0298 - val_loss: 2.8556e-04 - val_rmse: 0.0169\n",
      "Epoch 6/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8959e-04 - rmse: 0.0298 - val_loss: 2.8421e-04 - val_rmse: 0.0169\n",
      "Epoch 7/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8967e-04 - rmse: 0.0298 - val_loss: 2.7713e-04 - val_rmse: 0.0166\n",
      "Epoch 8/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8926e-04 - rmse: 0.0298 - val_loss: 2.7728e-04 - val_rmse: 0.0167\n",
      "Epoch 9/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8962e-04 - rmse: 0.0298 - val_loss: 2.7860e-04 - val_rmse: 0.0167\n",
      "Epoch 10/10\n",
      "5567/5567 [==============================] - 17s 3ms/step - loss: 8.8928e-04 - rmse: 0.0298 - val_loss: 2.7900e-04 - val_rmse: 0.0167\n",
      "00:31:53 | fold:11 | Mean:-0.0000 | Median: 0.0118\n",
      "Epoch 1/10\n",
      "5571/5571 [==============================] - 18s 3ms/step - loss: 9.7680e-04 - rmse: 0.0313 - val_loss: 3.2680e-04 - val_rmse: 0.0181\n",
      "Epoch 2/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3533e-04 - rmse: 0.0306 - val_loss: 3.2695e-04 - val_rmse: 0.0181\n",
      "Epoch 3/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3473e-04 - rmse: 0.0306 - val_loss: 3.2830e-04 - val_rmse: 0.0181\n",
      "Epoch 4/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3395e-04 - rmse: 0.0306 - val_loss: 3.2896e-04 - val_rmse: 0.0181\n",
      "Epoch 5/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3455e-04 - rmse: 0.0306 - val_loss: 3.2938e-04 - val_rmse: 0.0181\n",
      "Epoch 6/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3452e-04 - rmse: 0.0306 - val_loss: 3.3007e-04 - val_rmse: 0.0182\n",
      "Epoch 7/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3437e-04 - rmse: 0.0306 - val_loss: 3.3128e-04 - val_rmse: 0.0182\n",
      "Epoch 8/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3411e-04 - rmse: 0.0306 - val_loss: 3.2754e-04 - val_rmse: 0.0181\n",
      "Epoch 9/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3407e-04 - rmse: 0.0306 - val_loss: 3.2721e-04 - val_rmse: 0.0181\n",
      "Epoch 10/10\n",
      "5571/5571 [==============================] - 17s 3ms/step - loss: 9.3410e-04 - rmse: 0.0306 - val_loss: 3.3254e-04 - val_rmse: 0.0182\n",
      "00:34:50 | fold:12 | Mean: 0.0080 | Median: 0.0203\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "checkpoint_path = results_path / f'lookahead_{lookahead:02d}'\n",
    "if not checkpoint_path.exists():\n",
    "    checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "start = time()\n",
    "ic  = []\n",
    "epoch = 10\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(features)):\n",
    "    X_train, y_train, X_val, y_val = get_train_valid_data(features, target, train_idx, test_idx)\n",
    "    preds = y_val.to_frame('actual')\n",
    "    r = pd.DataFrame(index=y_val.index.unique(level='date')).sort_index()\n",
    "    model = make_model(filter1=16, act1='relu', filter2=32, act2='relu', do1=.25, do2=.5, dense=32)\n",
    "    best_mean = best_median = -np.inf\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val),\n",
    "              epochs=epoch, shuffle=True, workers=6)\n",
    "    model.save_weights((checkpoint_path / f'ckpt_{fold}').as_posix())\n",
    "    preds[epoch] = model.predict(X_val).squeeze()\n",
    "    r[epoch] = preds.groupby(level='date').apply(lambda x: spearmanr(x.actual, x[epoch])[0]).to_frame(epoch)\n",
    "    print(f'{format_time(time()-start)} | fold:{fold + 1:02d} | Mean:{r[epoch].mean():7.4f} | Median:{r[epoch].median():7.4f}')\n",
    "\n",
    "    # source code has been changed simply because of the memory problem\n",
    "    # for epoch in range(20):\n",
    "    #     model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val),\n",
    "    #               epochs=epoch + 1, initial_epoch=epoch, verbose=0, shuffle=True, workers=6)\n",
    "    #     model.save_weights((checkpoint_path / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "    #     preds[epoch] = model.predict(X_val).squeeze()\n",
    "    #     r[epoch] = preds.groupby(level='date').apply(lambda x: spearmanr(x.actual, x[epoch])[0]).to_frame(epoch)\n",
    "    #     print(f'{format_time(time()-start)} | fold:{fold + 1:02d} | epoch:{epoch + 1:02d} | Mean:{r[epoch].mean():7.4f} | Median:{r[epoch].median():7.4f}')\n",
    "    ic.append(r.assign(fold=fold))\n",
    "    \n",
    "    if fold > 10:\n",
    "        break\n",
    "\n",
    "ic = pd.concat(ic)\n",
    "ic.to_csv(checkpoint_path / 'ic.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate results\n",
    "ic.groupby('fold').mean().boxplot();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "            10\nfold          \n0    -0.014330\n1    -0.006414\n2    -0.013591\n3     0.015334\n4     0.029792\n5    -0.006340\n6     0.046164\n7     0.018540\n8     0.001946\n9     0.020180\n10   -0.000001\n11    0.008016",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n    </tr>\n    <tr>\n      <th>fold</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.014330</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.006414</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.013591</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.015334</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.029792</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.006340</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.046164</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.018540</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.001946</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.020180</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-0.000001</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.008016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic.groupby('fold').mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ic.groupby('fold').mean().mean().sort_index().plot.bar(rot=0);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1296x720 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = sns.diverging_palette(h_neg=20, h_pos=210)\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "sns.heatmap(ic.groupby('fold').mean().mul(100), ax=ax, center=0, cmap=cmap, annot=True, fmt='.1f')\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "# def generate_predictions(epoch):\n",
    "def generate_predictions():\n",
    "    predictions = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(features)):\n",
    "        if fold == 12:\n",
    "            break\n",
    "        X_train, y_train, X_val, y_val = get_train_valid_data(features, target, train_idx, test_idx)\n",
    "        preds = y_val.to_frame('actual')\n",
    "        model = make_model(filter1=16, act1='relu', filter2=32, act2='relu', do1=.25, do2=.5, dense=32)\n",
    "        # status = model.load_weights((checkpoint_path / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "        status = model.load_weights((checkpoint_path / f'ckpt_{fold}').as_posix())\n",
    "        status.expect_partial()\n",
    "        predictions.append(pd.Series(model.predict(X_val).squeeze(), index=y_val.index))\n",
    "    return pd.concat(predictions)\n",
    "\n",
    "preds = {}\n",
    "for i in enumerate(ic.drop('fold', axis=1).mean().nlargest(3).index):\n",
    "    preds[i] = generate_predictions()\n",
    "with pd.HDFStore(results_path / 'predictions.h5') as store:\n",
    "    store.put('predictions', pd.DataFrame(preds).sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "           prediction                                                    \\\nsymbol              A       AAL       AAP      AAPL      ABBV       ABC   \ndate                                                                      \n2013-03-25  -0.001340 -0.001364 -0.001362 -0.001363       NaN -0.001370   \n2013-03-26  -0.001348 -0.001364 -0.001367 -0.001359       NaN -0.001372   \n2013-03-27  -0.001349 -0.001364 -0.001365 -0.001343       NaN -0.001372   \n2013-03-28  -0.001349 -0.001370 -0.001373 -0.001336       NaN -0.001382   \n2013-04-01  -0.001343 -0.001362 -0.001365 -0.001332       NaN -0.001384   \n...               ...       ...       ...       ...       ...       ...   \n2018-03-20   0.000157  0.000152  0.000155  0.000167  0.000146  0.000152   \n2018-03-21   0.000168  0.000156  0.000149  0.000173  0.000154  0.000154   \n2018-03-22   0.000164  0.000152  0.000148  0.000178  0.000130  0.000153   \n2018-03-23   0.000168  0.000153  0.000145  0.000187  0.000136  0.000166   \n2018-03-26   0.000171  0.000158  0.000141  0.000177  0.000156  0.000178   \n\n                                                    ...                      \\\nsymbol           ABT       ACE       ACI       ACN  ...       ITW       IVZ   \ndate                                                ...                       \n2013-03-25 -0.001346 -0.001361 -0.001355 -0.001337  ... -0.001344 -0.001347   \n2013-03-26 -0.001355 -0.001364 -0.001356 -0.001341  ... -0.001344 -0.001358   \n2013-03-27 -0.001360 -0.001364 -0.001360 -0.001343  ... -0.001342 -0.001354   \n2013-03-28 -0.001366 -0.001368 -0.001346 -0.001351  ... -0.001345 -0.001358   \n2013-04-01 -0.001366 -0.001364 -0.001337 -0.001349  ... -0.001345 -0.001344   \n...              ...       ...       ...       ...  ...       ...       ...   \n2018-03-20  0.000135       NaN       NaN  0.000131  ...  0.000130  0.000138   \n2018-03-21  0.000142       NaN       NaN  0.000136  ...  0.000129  0.000137   \n2018-03-22  0.000178       NaN       NaN  0.000156  ...  0.000150  0.000138   \n2018-03-23  0.000166       NaN       NaN  0.000167  ...  0.000153  0.000141   \n2018-03-26  0.000159       NaN       NaN  0.000166  ...  0.000163  0.000133   \n\n                                                                        \\\nsymbol          JBHT       JBL      JBLU       JCI       JCP      JDSU   \ndate                                                                     \n2013-03-25 -0.001355 -0.001332 -0.001362 -0.001345 -0.001331 -0.001354   \n2013-03-26 -0.001355 -0.001331 -0.001359 -0.001347 -0.001332 -0.001354   \n2013-03-27 -0.001355 -0.001332 -0.001363 -0.001346 -0.001333 -0.001354   \n2013-03-28 -0.001361 -0.001336 -0.001362 -0.001359 -0.001332 -0.001355   \n2013-04-01 -0.001347 -0.001332 -0.001346 -0.001353 -0.001332 -0.001351   \n...              ...       ...       ...       ...       ...       ...   \n2018-03-20  0.000143       NaN  0.000133  0.000166  0.000206       NaN   \n2018-03-21  0.000142       NaN  0.000152  0.000180  0.000208       NaN   \n2018-03-22  0.000156       NaN  0.000151  0.000165  0.000210       NaN   \n2018-03-23  0.000163       NaN  0.000150  0.000168  0.000191       NaN   \n2018-03-26  0.000152       NaN  0.000158  0.000162  0.000196       NaN   \n\n                                \nsymbol           JEC       JNJ  \ndate                            \n2013-03-25 -0.001382 -0.001374  \n2013-03-26 -0.001393 -0.001389  \n2013-03-27 -0.001395 -0.001392  \n2013-03-28 -0.001398 -0.001395  \n2013-04-01 -0.001367 -0.001397  \n...              ...       ...  \n2018-03-20       NaN  0.000177  \n2018-03-21       NaN  0.000178  \n2018-03-22       NaN  0.000169  \n2018-03-23       NaN  0.000169  \n2018-03-26       NaN  0.000189  \n\n[1260 rows x 294 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"21\" halign=\"left\">prediction</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th>A</th>\n      <th>AAL</th>\n      <th>AAP</th>\n      <th>AAPL</th>\n      <th>ABBV</th>\n      <th>ABC</th>\n      <th>ABT</th>\n      <th>ACE</th>\n      <th>ACI</th>\n      <th>ACN</th>\n      <th>...</th>\n      <th>ITW</th>\n      <th>IVZ</th>\n      <th>JBHT</th>\n      <th>JBL</th>\n      <th>JBLU</th>\n      <th>JCI</th>\n      <th>JCP</th>\n      <th>JDSU</th>\n      <th>JEC</th>\n      <th>JNJ</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-03-25</th>\n      <td>-0.001340</td>\n      <td>-0.001364</td>\n      <td>-0.001362</td>\n      <td>-0.001363</td>\n      <td>NaN</td>\n      <td>-0.001370</td>\n      <td>-0.001346</td>\n      <td>-0.001361</td>\n      <td>-0.001355</td>\n      <td>-0.001337</td>\n      <td>...</td>\n      <td>-0.001344</td>\n      <td>-0.001347</td>\n      <td>-0.001355</td>\n      <td>-0.001332</td>\n      <td>-0.001362</td>\n      <td>-0.001345</td>\n      <td>-0.001331</td>\n      <td>-0.001354</td>\n      <td>-0.001382</td>\n      <td>-0.001374</td>\n    </tr>\n    <tr>\n      <th>2013-03-26</th>\n      <td>-0.001348</td>\n      <td>-0.001364</td>\n      <td>-0.001367</td>\n      <td>-0.001359</td>\n      <td>NaN</td>\n      <td>-0.001372</td>\n      <td>-0.001355</td>\n      <td>-0.001364</td>\n      <td>-0.001356</td>\n      <td>-0.001341</td>\n      <td>...</td>\n      <td>-0.001344</td>\n      <td>-0.001358</td>\n      <td>-0.001355</td>\n      <td>-0.001331</td>\n      <td>-0.001359</td>\n      <td>-0.001347</td>\n      <td>-0.001332</td>\n      <td>-0.001354</td>\n      <td>-0.001393</td>\n      <td>-0.001389</td>\n    </tr>\n    <tr>\n      <th>2013-03-27</th>\n      <td>-0.001349</td>\n      <td>-0.001364</td>\n      <td>-0.001365</td>\n      <td>-0.001343</td>\n      <td>NaN</td>\n      <td>-0.001372</td>\n      <td>-0.001360</td>\n      <td>-0.001364</td>\n      <td>-0.001360</td>\n      <td>-0.001343</td>\n      <td>...</td>\n      <td>-0.001342</td>\n      <td>-0.001354</td>\n      <td>-0.001355</td>\n      <td>-0.001332</td>\n      <td>-0.001363</td>\n      <td>-0.001346</td>\n      <td>-0.001333</td>\n      <td>-0.001354</td>\n      <td>-0.001395</td>\n      <td>-0.001392</td>\n    </tr>\n    <tr>\n      <th>2013-03-28</th>\n      <td>-0.001349</td>\n      <td>-0.001370</td>\n      <td>-0.001373</td>\n      <td>-0.001336</td>\n      <td>NaN</td>\n      <td>-0.001382</td>\n      <td>-0.001366</td>\n      <td>-0.001368</td>\n      <td>-0.001346</td>\n      <td>-0.001351</td>\n      <td>...</td>\n      <td>-0.001345</td>\n      <td>-0.001358</td>\n      <td>-0.001361</td>\n      <td>-0.001336</td>\n      <td>-0.001362</td>\n      <td>-0.001359</td>\n      <td>-0.001332</td>\n      <td>-0.001355</td>\n      <td>-0.001398</td>\n      <td>-0.001395</td>\n    </tr>\n    <tr>\n      <th>2013-04-01</th>\n      <td>-0.001343</td>\n      <td>-0.001362</td>\n      <td>-0.001365</td>\n      <td>-0.001332</td>\n      <td>NaN</td>\n      <td>-0.001384</td>\n      <td>-0.001366</td>\n      <td>-0.001364</td>\n      <td>-0.001337</td>\n      <td>-0.001349</td>\n      <td>...</td>\n      <td>-0.001345</td>\n      <td>-0.001344</td>\n      <td>-0.001347</td>\n      <td>-0.001332</td>\n      <td>-0.001346</td>\n      <td>-0.001353</td>\n      <td>-0.001332</td>\n      <td>-0.001351</td>\n      <td>-0.001367</td>\n      <td>-0.001397</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-03-20</th>\n      <td>0.000157</td>\n      <td>0.000152</td>\n      <td>0.000155</td>\n      <td>0.000167</td>\n      <td>0.000146</td>\n      <td>0.000152</td>\n      <td>0.000135</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000131</td>\n      <td>...</td>\n      <td>0.000130</td>\n      <td>0.000138</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.000133</td>\n      <td>0.000166</td>\n      <td>0.000206</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000177</td>\n    </tr>\n    <tr>\n      <th>2018-03-21</th>\n      <td>0.000168</td>\n      <td>0.000156</td>\n      <td>0.000149</td>\n      <td>0.000173</td>\n      <td>0.000154</td>\n      <td>0.000154</td>\n      <td>0.000142</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000136</td>\n      <td>...</td>\n      <td>0.000129</td>\n      <td>0.000137</td>\n      <td>0.000142</td>\n      <td>NaN</td>\n      <td>0.000152</td>\n      <td>0.000180</td>\n      <td>0.000208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000178</td>\n    </tr>\n    <tr>\n      <th>2018-03-22</th>\n      <td>0.000164</td>\n      <td>0.000152</td>\n      <td>0.000148</td>\n      <td>0.000178</td>\n      <td>0.000130</td>\n      <td>0.000153</td>\n      <td>0.000178</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000156</td>\n      <td>...</td>\n      <td>0.000150</td>\n      <td>0.000138</td>\n      <td>0.000156</td>\n      <td>NaN</td>\n      <td>0.000151</td>\n      <td>0.000165</td>\n      <td>0.000210</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000169</td>\n    </tr>\n    <tr>\n      <th>2018-03-23</th>\n      <td>0.000168</td>\n      <td>0.000153</td>\n      <td>0.000145</td>\n      <td>0.000187</td>\n      <td>0.000136</td>\n      <td>0.000166</td>\n      <td>0.000166</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000167</td>\n      <td>...</td>\n      <td>0.000153</td>\n      <td>0.000141</td>\n      <td>0.000163</td>\n      <td>NaN</td>\n      <td>0.000150</td>\n      <td>0.000168</td>\n      <td>0.000191</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000169</td>\n    </tr>\n    <tr>\n      <th>2018-03-26</th>\n      <td>0.000171</td>\n      <td>0.000158</td>\n      <td>0.000141</td>\n      <td>0.000177</td>\n      <td>0.000156</td>\n      <td>0.000178</td>\n      <td>0.000159</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000166</td>\n      <td>...</td>\n      <td>0.000163</td>\n      <td>0.000133</td>\n      <td>0.000152</td>\n      <td>NaN</td>\n      <td>0.000158</td>\n      <td>0.000162</td>\n      <td>0.000196</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000189</td>\n    </tr>\n  </tbody>\n</table>\n<p>1260 rows × 294 columns</p>\n</div>"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = pd.DataFrame(preds)\n",
    "df_predictions.columns = ['prediction']\n",
    "df_predictions = df_predictions.swaplevel().unstack()\n",
    "df_predictions.sort_values(by='date', ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}