{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:13.447415500Z",
     "start_time": "2023-09-26T00:42:54.561718500Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import (Flatten, Dense, BatchNormalization, Activation, Concatenate)\n",
    "from tensorflow.keras import backend as K\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "    # tf.config.experimental.set_virtual_device_configuration(gpu_devices[0],\n",
    "    # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*6)])\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "data_path = Path('data', 'image', 'svhn')\n",
    "\n",
    "results_path = Path('results', 'svhn')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:13.502490100Z",
     "start_time": "2023-09-26T00:43:13.451405500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Settings\n",
    "IMG_SIZE = 32\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "SEQ_LENGTH = 4\n",
    "N_CLASSES = 11\n",
    "\n",
    "# Load Data\n",
    "X_train = np.load(data_path / 'X_train.npy')\n",
    "y_train = np.load(data_path / 'y_train.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:17.722430100Z",
     "start_time": "2023-09-26T00:43:13.497502500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0     4\n1    10\n2    11\n3    11\n4    11\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[y_train[:, 0] < 5]\n",
    "y_train = y_train[y_train[:, 0] < 5, :5]\n",
    "y_train[:, 0] -= 1\n",
    "X_test = np.load(data_path / 'X_test.npy')\n",
    "y_test = np.load(data_path / 'y_test.npy')\n",
    "X_test = X_test[y_test[:, 0] < 5]\n",
    "y_test = y_test[y_test[:, 0] < 5, :5]\n",
    "y_test[:, 0] -= 1\n",
    "pd.DataFrame(y_train).nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:19.458701100Z",
     "start_time": "2023-09-26T00:43:17.725422200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(33392, 5)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:19.491613100Z",
     "start_time": "2023-09-26T00:43:19.432769900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Best Architecture\n",
    "digit_pos = {1: [4, 14], 2: [14, 25], 3: [25, 36], 4: [36, 47]}\n",
    "\n",
    "def weighted_accuracy(y_true, y_pred):\n",
    "    n_digits_pred = K.argmax(y_pred[:, :SEQ_LENGTH], axis=1)\n",
    "\n",
    "    digit_preds = {}\n",
    "    for digit, (start, end) in digit_pos.items():\n",
    "        digit_preds[digit] = K.argmax(y_pred[:, start:end], axis=1)\n",
    "    preds = tf.dtypes.cast(tf.stack((n_digits_pred, digit_preds[1], digit_preds[2], digit_preds[3],\n",
    "                                     digit_preds[4]), axis=1), tf.float32)\n",
    "\n",
    "    return K.mean(K.sum(tf.dtypes.cast(K.equal(y_true, preds), tf.int64), axis=1) / 5)\n",
    "\n",
    "def weighted_entropy(y_true, y_pred):\n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    n_digits = y_pred[:, :SEQ_LENGTH]\n",
    "\n",
    "    digits = {}\n",
    "    for digit, (start, end) in digit_pos.items():\n",
    "        digits[digit] = y_pred[:, start:end]\n",
    "    return (cce(y_true[:, 0], n_digits) + cce(y_true[:, 1], digits[1]) + cce(y_true[:, 2], digits[2]) +\n",
    "            cce(y_true[:, 3], digits[3]) + cce(y_true[:, 4], digits[4])) / 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:19.492615Z",
     "start_time": "2023-09-26T00:43:19.451719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "vgg16 = VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "vgg16.trainable = False\n",
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "n_digits = Dense(SEQ_LENGTH, activation='softmax', name='n_digits')(x)\n",
    "digit1 = Dense(N_CLASSES-1, activation='softmax', name='d1')(x)\n",
    "digit2 = Dense(N_CLASSES, activation='softmax', name='d2')(x)\n",
    "digit3 = Dense(N_CLASSES, activation='softmax', name='d3')(x)\n",
    "digit4 = Dense(N_CLASSES, activation='softmax', name='d4')(x)\n",
    "predictions = Concatenate()([n_digits, digit1, digit2, digit3, digit4])\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=weighted_entropy, metrics=[weighted_accuracy])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:21.822083Z",
     "start_time": "2023-09-26T00:43:19.463687100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Define Callbacks\n",
    "svhn_path = (results_path / 'svhn.weights.best.hdf5').as_posix()\n",
    "checkpointer = ModelCheckpoint(filepath=svhn_path, verbose=1, monitor='val_weighted_accuracy',\n",
    "                               save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_weighted_accuracy', patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T00:43:21.838039800Z",
     "start_time": "2023-09-26T00:43:21.825074800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function weighted_entropy at 0x000002954A0AD550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function weighted_entropy at 0x000002954A0AD550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function weighted_accuracy at 0x000002954A0ADF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function weighted_accuracy at 0x000002954A0ADF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "940/940 [==============================] - ETA: 0s - loss: nan - weighted_accuracy: 0.0681\n",
      "Epoch 00001: val_weighted_accuracy improved from -inf to 0.05925, saving model to results/svhn\\svhn.weights.best.hdf5\n",
      "940/940 [==============================] - 259s 276ms/step - loss: nan - weighted_accuracy: 0.0681 - val_loss: nan - val_weighted_accuracy: 0.0592\n",
      "Epoch 2/50\n",
      "940/940 [==============================] - ETA: 0s - loss: nan - weighted_accuracy: 0.0606\n",
      "Epoch 00002: val_weighted_accuracy did not improve from 0.05925\n",
      "940/940 [==============================] - 256s 273ms/step - loss: nan - weighted_accuracy: 0.0606 - val_loss: nan - val_weighted_accuracy: 0.0592\n",
      "Epoch 3/50\n",
      "940/940 [==============================] - ETA: 0s - loss: nan - weighted_accuracy: 0.0605\n",
      "Epoch 00003: val_weighted_accuracy did not improve from 0.05925\n",
      "940/940 [==============================] - 258s 274ms/step - loss: nan - weighted_accuracy: 0.0605 - val_loss: nan - val_weighted_accuracy: 0.0592\n",
      "Epoch 4/50\n",
      "940/940 [==============================] - ETA: 0s - loss: nan - weighted_accuracy: 0.0605\n",
      "Epoch 00004: val_weighted_accuracy did not improve from 0.05925\n",
      "940/940 [==============================] - 256s 273ms/step - loss: nan - weighted_accuracy: 0.0605 - val_loss: nan - val_weighted_accuracy: 0.0592\n",
      "Epoch 5/50\n",
      "939/940 [============================>.] - ETA: 0s - loss: nan - weighted_accuracy: 0.0605\n",
      "Epoch 00005: val_weighted_accuracy did not improve from 0.05925\n",
      "940/940 [==============================] - 256s 272ms/step - loss: nan - weighted_accuracy: 0.0606 - val_loss: nan - val_weighted_accuracy: 0.0592\n",
      "Epoch 6/50\n",
      "940/940 [==============================] - ETA: 0s - loss: nan - weighted_accuracy: 0.0605\n",
      "Epoch 00006: val_weighted_accuracy did not improve from 0.05925\n",
      "940/940 [==============================] - 253s 269ms/step - loss: nan - weighted_accuracy: 0.0605 - val_loss: nan - val_weighted_accuracy: 0.0592\n"
     ]
    }
   ],
   "source": [
    "# Train Transfer Model\n",
    "epochs = 50\n",
    "result = model.fit(x=X_train, y=y_train, validation_split=.1, batch_size=32, epochs=epochs, verbose=1,\n",
    "                    callbacks=[checkpointer, early_stopping], workers=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T01:09:07.246035100Z",
     "start_time": "2023-09-26T00:43:21.840034900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 99s 241ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Results\n",
    "metrics = pd.DataFrame(result.history)\n",
    "initial_epochs = len(metrics)\n",
    "y_pred = model.predict(X_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:47.124180400Z",
     "start_time": "2023-09-26T01:09:07.248030800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.19003520587785092"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_digits = y_pred[:, :SEQ_LENGTH]\n",
    "digits = {}\n",
    "for digit, (start, end) in digit_pos.items():\n",
    "    digits[digit] = y_pred[:, start:end]\n",
    "\n",
    "(y_test[:, 0] == np.argmax(n_digits, axis=1)).sum()/len(n_digits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:47.172052300Z",
     "start_time": "2023-09-26T01:10:47.127171800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2483,    0,    0,    0],\n       [8356,    0,    0,    0],\n       [2081,    0,    0,    0],\n       [ 146,    0,    0,    0]], dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test[:, 0], y_pred=np.argmax(n_digits, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:47.221918600Z",
     "start_time": "2023-09-26T01:10:47.175043900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = np.zeros_like(y_test)\n",
    "accuracy[:, 0] = (y_test[:, 0] == np.argmax(n_digits, axis=1))\n",
    "\n",
    "for i in range(1, 5):\n",
    "    accuracy[:, i] = (y_test[:, i] == np.argmax(digits[i], axis=1))\n",
    "\n",
    "acc_by_output = {}\n",
    "for i in range(5):\n",
    "    acc_by_output[i] = accuracy[:, i].sum()/accuracy[:, i].shape[0]\n",
    "\n",
    "acc_up_to_out = {}\n",
    "for i in range(1, 6):\n",
    "    r = accuracy[:, :i].all(1)\n",
    "    acc_up_to_out[i-1] = r.sum()/r.shape[0]\n",
    "\n",
    "pd.DataFrame({'acc1': acc_by_output, 'acc2': acc_up_to_out}).plot.bar()\n",
    "sns.despine();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:48.379862700Z",
     "start_time": "2023-09-26T01:10:47.220921300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss': [nan, nan, nan, nan, nan, nan],\n 'weighted_accuracy': [0.06807181239128113,\n  0.0605585090816021,\n  0.060512006282806396,\n  0.060511961579322815,\n  0.060558516532182693,\n  0.06051196530461311],\n 'val_loss': [nan, nan, nan, nan, nan, nan],\n 'val_weighted_accuracy': [0.05924604833126068,\n  0.05924604833126068,\n  0.05924604833126068,\n  0.05924604833126068,\n  0.05924604833126068,\n  0.05924604833126068]}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:48.390834Z",
     "start_time": "2023-09-26T01:10:48.378869200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "n_digits (Dense)                (None, 4)            516         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "d1 (Dense)                      (None, 10)           1290        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "d2 (Dense)                      (None, 11)           1419        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "d3 (Dense)                      (None, 11)           1419        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "d4 (Dense)                      (None, 11)           1419        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 47)           0           n_digits[0][0]                   \n",
      "                                                                 d1[0][0]                         \n",
      "                                                                 d2[0][0]                         \n",
      "                                                                 d3[0][0]                         \n",
      "                                                                 d4[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 14,888,559\n",
      "Trainable params: 172,079\n",
      "Non-trainable params: 14,716,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:48.401805100Z",
     "start_time": "2023-09-26T01:10:48.386844200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T01:10:48.482588500Z",
     "start_time": "2023-09-26T01:10:48.400806700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/56\n"
     ]
    }
   ],
   "source": [
    "# # Fine Tune VGG16 weights\n",
    "# vgg16.trainable = True\n",
    "# # Fine-tune from this layer onwards\n",
    "# start_fine_tuning_at = 1\n",
    "# \n",
    "# # Freeze all the layers before the `fine_tune_at` layer\n",
    "# for layer in vgg16.layers[:start_fine_tuning_at]:\n",
    "#     layer.trainable =  False\n",
    "# \n",
    "# model.compile(optimizer='adam', loss=weighted_entropy, metrics=[weighted_accuracy])\n",
    "# \n",
    "# fine_tune_epochs = 50\n",
    "# total_epochs = initial_epochs + fine_tune_epochs\n",
    "# \n",
    "# result_fine_tune = model.fit(x=X_train, y=y_train, validation_split=.1, batch_size=32, epochs=total_epochs, initial_epoch=initial_epochs, callbacks=[early_stopping], workers=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-26T01:10:48.414769200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metrics_tuned = metrics.append(pd.DataFrame(result_fine_tune.history), ignore_index=True)\n",
    "# metrics_tuned.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(ncols=2, figsize=(15, 4))\n",
    "# metrics_tuned[['loss', 'val_loss']].plot(ax=axes[1], title='Cross-Entropy Loss')\n",
    "# metrics_tuned[['weighted_accuracy', 'val_weighted_accuracy']].plot(ax=axes[0], title=f'Accuracy (Best: {metrics_tuned.val_weighted_accuracy.max():.2%})')\n",
    "# axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "# axes[0].set_ylabel('Accuracy')\n",
    "# axes[1].set_ylabel('Loss')\n",
    "# \n",
    "# for ax in axes:\n",
    "#     ax.axvline(14, ls='--', lw=1, c='k')\n",
    "#     ax.legend(['Training', 'Validation', 'Start Fine Tuning'])\n",
    "#     ax.set_xlabel('Epoch')\n",
    "# \n",
    "# fig.tight_layout()\n",
    "# fig.savefig(results_path / 'transfer_learning_svhn');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
